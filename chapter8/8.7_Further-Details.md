## 8.7 更多细节（*Further Details*）

在这一节中，我们将总结数据和模型的其余几个细节，首先是数据。由于我们提出的算法是有监督的，所以标注数据对于训练和测试是至关重要的。现在我们有各种各样的数据集用于词性标注和 NER。在撰写本文时，Universal Dependencies（UD）数据集 (Nivre et al., 2016b)[^1] 有 92 种语言的 POS 标注语料，Penn Treebanks 也有英文、中文和阿拉伯文版本。OntoNotes NER 语料库也有英文、中文和阿拉伯文版本 (Hovy et al, 2006)[^2]。同时也有在特定领域的 NER 语料库，例如生物医学领域 (Bada et al., 2012)[^3] 和文学文本 (Bamman et al., 2019)[^4]。

### 8.7.1 双向性（*Bidirectionality*）

上述 CRF 和 HMM 架构的一个问题是，这些模型是完全从左到右运行的。虽然维特比算法允许当前决策间接地受到未来决策的影响，但如果预测单词 $w_i$ 的标签时能够直接使用未来标签 $t_{i+1}$ 和 $t_{i+2}$ 的信息，那将会有更大的帮助。

另外，任何序列模型都可以通过使用多个通道变成一个双向模型。例如，第一个通道只使用左边词的词性特征。在第二个通道中，可以使用所有单词的标签，包括右边的单词。另外，标注器也可以运行两次，一次从左到右，一次从右到左。在维特比解码中，标注器会选择两个序列中得分较高的序列（从左到右或从右到左）。双向模型对于神经模型来说是很常用的，正如我们将在第九章介绍的 biLSTM 模型中看到的那样。

### 8.7.2 基于规则的方法（*Rule-based Methods*）

[^1]: Nivre, J., de Marneffe, M.-C., Ginter, F., Goldberg, Y., Hajiˇc, J., Manning, C. D., McDonald, R., Petrov, S., Pyysalo, S., Silveira, N., Tsarfaty, R., and Zeman, D. (2016b). Universal Dependencies v1: A multilingual treebank collection. LREC.  
[^2]: Hovy, E. H., Marcus, M. P., Palmer, M., Ramshaw, L. A., and Weischedel, R. (2006). Ontonotes: The 90% solution. HLT-NAACL.  
[^3]: Bada, M., Eckert, M., Evans, D., Garcia, K., Shipley, K., Sitnikov, D., Baumgartner, W. A., Cohen, K. B., Verspoor, K., Blake, J. A., and Hunter, L. E. (2012). Concept annotation in the craft corpus. BMC bioinformatics 13(1), 161.  
[^4]: Bamman, D., Popat, S., and Shen, S. (2019). An annotated dataset of literary entities. NAACL HLT.  
